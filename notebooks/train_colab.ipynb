{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SV-SCN Training Notebook\n",
                "\n",
                "Train the Single-View Shape Completion Network on Google Colab.\n",
                "\n",
                "**Requirements:**\n",
                "- GPU runtime (T4/V100/A100)\n",
                "- ~50GB disk space for data\n",
                "- 6-12 hours for full training\n",
                "\n",
                "**Quick Start:**\n",
                "1. Enable GPU: Runtime → Change runtime type → GPU\n",
                "2. Run all cells in order\n",
                "3. Checkpoints saved to Google Drive"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU\n",
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mount Google Drive for persistent storage\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Create project directory in Drive\n",
                "!mkdir -p /content/drive/MyDrive/svscn\n",
                "!mkdir -p /content/drive/MyDrive/svscn/checkpoints\n",
                "!mkdir -p /content/drive/MyDrive/svscn/data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone repository (or upload your code)\n",
                "# Option 1: From GitHub\n",
                "# !git clone https://github.com/yourusername/frozo-3d-model.git\n",
                "\n",
                "# Option 2: Upload from local\n",
                "# Use Colab file upload or copy from Drive\n",
                "!mkdir -p /content/frozo-3d-model\n",
                "%cd /content/frozo-3d-model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install torch>=2.0.0 numpy>=1.24.0 open3d>=0.17.0 trimesh>=4.0.0 \\\n",
                "    objaverse>=0.1.7 tqdm>=4.65.0 tensorboard>=2.14.0 scipy"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Prepare Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "sys.path.insert(0, '/content/frozo-3d-model')\n",
                "\n",
                "# Check if data already exists in Drive\n",
                "DATA_DIR = '/content/drive/MyDrive/svscn/data/combined'\n",
                "\n",
                "if os.path.exists(f'{DATA_DIR}/dataset_metadata.json'):\n",
                "    print('Dataset found in Drive!')\n",
                "else:\n",
                "    print('Dataset not found. Will prepare...')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Option A: Use placeholder data for quick testing\n",
                "USE_PLACEHOLDER = True  # Set to False for real data\n",
                "\n",
                "if USE_PLACEHOLDER:\n",
                "    from svscn.data.shapenet import download_shapenet_sample\n",
                "    from pathlib import Path\n",
                "    \n",
                "    LOCAL_DATA = Path('/content/data')\n",
                "    download_shapenet_sample(LOCAL_DATA / 'shapenet')\n",
                "    print('Placeholder data created!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Option B: Download Objaverse data (takes ~1-2 hours)\n",
                "# Only run if USE_PLACEHOLDER = False\n",
                "\n",
                "if not USE_PLACEHOLDER:\n",
                "    from svscn.data.dataset_manager import prepare_combined_dataset\n",
                "    from pathlib import Path\n",
                "    \n",
                "    prepare_combined_dataset(\n",
                "        output_dir=Path(DATA_DIR),\n",
                "        config=None  # Uses default config\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preprocess meshes to point clouds\n",
                "from svscn.data.preprocess import process_dataset\n",
                "from pathlib import Path\n",
                "\n",
                "if USE_PLACEHOLDER:\n",
                "    input_dir = Path('/content/data/shapenet')\n",
                "    output_dir = Path('/content/data/processed')\n",
                "else:\n",
                "    input_dir = Path(DATA_DIR) / 'raw'\n",
                "    output_dir = Path(DATA_DIR) / 'pointclouds'\n",
                "\n",
                "process_dataset(input_dir, output_dir, num_points=8192)\n",
                "print(f'Point clouds saved to {output_dir}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate training pairs (partial + full)\n",
                "from svscn.data.augment import process_to_training_data\n",
                "from pathlib import Path\n",
                "\n",
                "if USE_PLACEHOLDER:\n",
                "    full_dir = Path('/content/data/processed')\n",
                "    train_dir = Path('/content/data/training')\n",
                "else:\n",
                "    full_dir = Path(DATA_DIR) / 'pointclouds'\n",
                "    train_dir = Path(DATA_DIR) / 'training'\n",
                "\n",
                "num_pairs = process_to_training_data(\n",
                "    full_clouds_dir=full_dir,\n",
                "    output_dir=train_dir,\n",
                "    views_per_object=3\n",
                ")\n",
                "print(f'Created {num_pairs} training pairs')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Create Data Loaders"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from svscn.data.dataset import FurnitureDataset, create_data_loaders\n",
                "from pathlib import Path\n",
                "import torch\n",
                "\n",
                "if USE_PLACEHOLDER:\n",
                "    TRAIN_DATA = Path('/content/data/training')\n",
                "else:\n",
                "    TRAIN_DATA = Path(DATA_DIR) / 'training'\n",
                "\n",
                "# Create loaders\n",
                "train_dataset = FurnitureDataset(TRAIN_DATA, split='train')\n",
                "val_dataset = FurnitureDataset(TRAIN_DATA, split='val')\n",
                "\n",
                "train_loader = torch.utils.data.DataLoader(\n",
                "    train_dataset, batch_size=32, shuffle=True, num_workers=2\n",
                ")\n",
                "val_loader = torch.utils.data.DataLoader(\n",
                "    val_dataset, batch_size=32, shuffle=False, num_workers=2\n",
                ")\n",
                "\n",
                "print(f'Train samples: {len(train_dataset)}')\n",
                "print(f'Val samples: {len(val_dataset)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize a sample\n",
                "import matplotlib.pyplot as plt\n",
                "from mpl_toolkits.mplot3d import Axes3D\n",
                "\n",
                "sample = train_dataset[0]\n",
                "partial = sample['partial'].numpy()\n",
                "full = sample['full'].numpy()\n",
                "\n",
                "fig = plt.figure(figsize=(12, 5))\n",
                "\n",
                "ax1 = fig.add_subplot(121, projection='3d')\n",
                "ax1.scatter(partial[:, 0], partial[:, 1], partial[:, 2], s=1, c='blue')\n",
                "ax1.set_title(f'Partial ({partial.shape[0]} points)')\n",
                "\n",
                "ax2 = fig.add_subplot(122, projection='3d')\n",
                "ax2.scatter(full[:, 0], full[:, 1], full[:, 2], s=0.5, c='green')\n",
                "ax2.set_title(f'Full ({full.shape[0]} points)')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Initialize Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from svscn.models import SVSCN\n",
                "\n",
                "# Create model\n",
                "model = SVSCN(\n",
                "    num_classes=3,\n",
                "    input_points=2048,\n",
                "    output_points=8192\n",
                ")\n",
                "\n",
                "# Move to GPU\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "model = model.to(device)\n",
                "\n",
                "# Count parameters\n",
                "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "print(f'Model: SVSCN')\n",
                "print(f'Parameters: {num_params:,}')\n",
                "print(f'Device: {device}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from svscn.training import Trainer\n",
                "from pathlib import Path\n",
                "\n",
                "# Checkpoint directory - save to Drive for persistence\n",
                "CHECKPOINT_DIR = Path('/content/drive/MyDrive/svscn/checkpoints')\n",
                "LOG_DIR = Path('/content/logs')\n",
                "\n",
                "# Create trainer\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    train_loader=train_loader,\n",
                "    val_loader=val_loader,\n",
                "    checkpoint_dir=CHECKPOINT_DIR,\n",
                "    log_dir=LOG_DIR,\n",
                "    device=device\n",
                ")\n",
                "\n",
                "print('Trainer initialized!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TensorBoard (run in separate cell)\n",
                "%load_ext tensorboard\n",
                "%tensorboard --logdir /content/logs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train!\n",
                "# For placeholder data, use fewer epochs\n",
                "EPOCHS = 10 if USE_PLACEHOLDER else 150\n",
                "\n",
                "summary = trainer.train(epochs=EPOCHS)\n",
                "\n",
                "print('\\nTraining Complete!')\n",
                "print(f'Best validation loss: {summary[\"best_val_loss\"]:.6f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Evaluate Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model\n",
                "best_ckpt = CHECKPOINT_DIR / 'best.pt'\n",
                "checkpoint = torch.load(best_ckpt)\n",
                "model.load_state_dict(checkpoint['model_state_dict'])\n",
                "model.eval()\n",
                "\n",
                "print(f'Loaded best model (epoch {checkpoint[\"epoch\"]})')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize predictions\n",
                "import matplotlib.pyplot as plt\n",
                "from mpl_toolkits.mplot3d import Axes3D\n",
                "\n",
                "# Get a sample\n",
                "sample = val_dataset[0]\n",
                "partial = sample['partial'].unsqueeze(0).to(device)\n",
                "full = sample['full'].numpy()\n",
                "class_id = sample['class_id'].unsqueeze(0).to(device)\n",
                "\n",
                "# Predict\n",
                "with torch.no_grad():\n",
                "    pred = model(partial, class_id)\n",
                "pred = pred.cpu().numpy()[0]\n",
                "\n",
                "# Plot\n",
                "fig = plt.figure(figsize=(15, 5))\n",
                "\n",
                "ax1 = fig.add_subplot(131, projection='3d')\n",
                "ax1.scatter(partial.cpu().numpy()[0, :, 0], \n",
                "            partial.cpu().numpy()[0, :, 1], \n",
                "            partial.cpu().numpy()[0, :, 2], s=1, c='blue')\n",
                "ax1.set_title('Input (Partial)')\n",
                "\n",
                "ax2 = fig.add_subplot(132, projection='3d')\n",
                "ax2.scatter(pred[:, 0], pred[:, 1], pred[:, 2], s=0.5, c='red')\n",
                "ax2.set_title('Prediction')\n",
                "\n",
                "ax3 = fig.add_subplot(133, projection='3d')\n",
                "ax3.scatter(full[:, 0], full[:, 1], full[:, 2], s=0.5, c='green')\n",
                "ax3.set_title('Ground Truth')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute metrics on validation set\n",
                "from svscn.models.losses import chamfer_distance, coverage_ratio\n",
                "\n",
                "total_cd = 0\n",
                "total_coverage = 0\n",
                "num_samples = 0\n",
                "\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    for batch in val_loader:\n",
                "        partial = batch['partial'].to(device)\n",
                "        full = batch['full'].to(device)\n",
                "        class_id = batch['class_id'].to(device)\n",
                "        \n",
                "        pred = model(partial, class_id)\n",
                "        \n",
                "        cd = chamfer_distance(pred, full, reduce='none')\n",
                "        cov = coverage_ratio(pred, full)\n",
                "        \n",
                "        total_cd += cd.sum().item()\n",
                "        total_coverage += cov.sum().item()\n",
                "        num_samples += len(batch['partial'])\n",
                "\n",
                "avg_cd = total_cd / num_samples\n",
                "avg_cov = total_coverage / num_samples\n",
                "\n",
                "print(f'Validation Metrics:')\n",
                "print(f'  Average Chamfer Distance: {avg_cd:.6f}')\n",
                "print(f'  Average Coverage: {avg_cov:.4f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Export Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save final model for inference\n",
                "from datetime import datetime\n",
                "\n",
                "version = datetime.now().strftime('%Y%m%d')\n",
                "export_path = CHECKPOINT_DIR / f'sv_scn_v0.1.0_{version}.pt'\n",
                "\n",
                "torch.save({\n",
                "    'model_state_dict': model.state_dict(),\n",
                "    'num_classes': 3,\n",
                "    'input_points': 2048,\n",
                "    'output_points': 8192,\n",
                "    'version': 'sv_scn_v0.1.0',\n",
                "    'metrics': {\n",
                "        'chamfer_distance': avg_cd,\n",
                "        'coverage': avg_cov\n",
                "    }\n",
                "}, export_path)\n",
                "\n",
                "print(f'Model exported to: {export_path}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download model from Colab\n",
                "from google.colab import files\n",
                "files.download(str(export_path))"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}